{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반화 성능도 있기 때문에 전체 데이터셋에 대해서 성능 평가를 해봐야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = (15106, 2770)\n",
      "y shape = (15106,)\n",
      "# features = 2770\n",
      "# L words = 15106\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../models/SVC (C=0.1) norml30_r15.pkl', 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "    \n",
    "from py.utils import load_data\n",
    "head = 'l30_r15'\n",
    "directory = '../data/'\n",
    "x, y, x_words, vocabs = load_data(head, directory)\n",
    "x = x.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  26,   32,   33, ...,   16, 1938,   95]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sample_r(li, topk=5):\n",
    "    nonzero = x[li,:].nonzero()[1]\n",
    "    base = min(50, len(nonzero)//2)\n",
    "    return [vocabs[r] for r in sorted(nonzero, key=lambda x:word_frequency[0,x], reverse=True)[base:base+topk]]\n",
    "\n",
    "word_frequency = x.sum(axis=0)\n",
    "word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5012)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# sparse matrix type\n",
    "print(classifier.dual_coef_.shape)\n",
    "\n",
    "# sum = 0 ?? alpha sum은 1아닌가?\n",
    "print(classifier.dual_coef_.data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5012, 2770)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vectors\n",
    "classifier.support_vectors_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33178869323447635"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of Support vector \n",
    "classifier.n_support_.sum() / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    3,     6,    26, ..., 15098, 15099, 15103], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector row id\n",
    "classifier.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞서(다) - ['자', '거나', '려고', '기로', '려는'] (-0.100)\n",
      "맡(다) - ['았기', '기에는', '으면서도', '으려', '았는데'] (-0.100)\n",
      "굽어보(다) - ['다', '기도', '니', '고는', '곤'] (-0.100)\n",
      "든(다) - ['다거나', '다면서', '다든가', '다고도', '다고들'] (-0.100)\n",
      "밉(다) - ['지도', '든', '기만', '질', '기까지'] (-0.100)\n",
      "따라다니(다) - ['다', '다가', '기도', '니', '기는'] (-0.100)\n",
      "떠나(다) - ['긴', '고도', '질', '신', '자는'] (-0.100)\n",
      "높이(다) - ['거나', '진', '지는', '지도', '려고'] (-0.100)\n",
      "다닌(다) - ['다면서', '다고는', '다지만', '다던', '답시고'] (-0.100)\n",
      "구(다) - ['느냐는', '웠던', '워진', '우면', '워지는'] (-0.100)\n",
      "식(다) - ['었지만', '을까', '어가는', '었으며', '어버린'] (-0.100)\n",
      "뚫어지(다) - ['면서', '도록'] (-0.100)\n",
      "두드려(다) - ['주지', '주면', '대는', '주며', '보려고'] (-0.100)\n",
      "다듬(다) - ['고자', '긴', '어져', '어지는', '는다고'] (-0.100)\n",
      "휘두르(다) - ['자', '거나', '지도', '려고', '고는'] (-0.100)\n",
      "되살려(다) - ['내는', '낼', '져야', '내고', '내어'] (-0.100)\n",
      "맛있(다) - ['기로', '기는', '었는데', '다며', '잖아'] (-0.100)\n",
      "걸맞(다) - ['지도', '는다는', '는다고', '게도', '았고'] (-0.100)\n",
      "생겨났(다) - ['는가', '을까', '는지도', '을지', '는가를'] (-0.100)\n",
      "샀(다) - ['거나', '는지', '더라도', '으나', '더니'] (-0.100)\n",
      "깨지(다) - ['자', '거나', '진', '구', '지는'] (-0.100)\n",
      "매달리(다) - ['려는', '기를', '듯', '기는', '듯이'] (-0.100)\n",
      "살아왔(다) - ['으며', '는지', '어도', '으니', '기에'] (-0.100)\n",
      "막(다) - ['지를', '느냐', '냐', '는다면', '으려는'] (-0.100)\n",
      "다가와(다) - ['야', '서는'] (-0.100)\n",
      "돌아다녀(다) - ['보면', '보니', '봐야', '야겠다고', '봐도'] (-0.100)\n",
      "찔리(다) - ['나', '도록', '기도', '거나', '지도'] (-0.100)\n",
      "적(다) - ['고자', '긴', '고도', '어서는', '는가'] (-0.100)\n",
      "처했(다) - ['다고', '지만', '는데', '음을', '었다고'] (-0.100)\n",
      "되짚(다) - ['어본', '어볼', '어보고', '어보는', '어보니'] (-0.100)\n",
      "꼬(다) - ['거나', '아서', '고는', '았던', '더니'] (-0.100)\n",
      "쓰리(다) - ['며', '다', '어서', '도록', '기도'] (-0.100)\n",
      "맴돌(다) - ['더니', '듯', '곤', '기만', '았을'] (-0.100)\n",
      "베(다) - ['어버린', '어내는', '어낸', '어가고', '달라고'] (-0.100)\n",
      "좋(다) - ['으니까', '으므로', '을까', '았다는', '겠지만'] (-0.100)\n",
      "비뚤(다) - ['어지고', '어질', '어지면', '어지기', '어져서'] (-0.100)\n",
      "무르익(다) - ['었을', '음을', '으면서', '었고', '었다고'] (-0.100)\n",
      "관해(다) - ['서나', '서가', '서라면', '서든', '서의'] (-0.100)\n",
      "잡아당기(다) - ['다', '다가', '기도', '니', '자'] (-0.100)\n",
      "허물어지(다) - ['던', '며', '도록', '거나', '듯'] (-0.100)\n"
     ]
    }
   ],
   "source": [
    "base = 0\n",
    "topk = 40\n",
    "for idx, l in sorted(enumerate(classifier.support_), key=lambda x:abs(classifier.dual_coef_[0,x[0]]), reverse=True)[base :base + topk]:\n",
    "    print('%s%s - %s (%.3f)' % (x_words[l], '' if y[l] == 1 else '(다)', get_sample_r(l), classifier.dual_coef_[0,idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of alphas = 2\n",
      "number of support vectors = 5012\n",
      "\n",
      "alpha= -0.100, count=2506 (0.500)\n",
      "alpha= 0.100, count=2506 (0.500)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "alpha_count = Counter(classifier.dual_coef_.data)\n",
    "print('number of alphas = %d' % len(alpha_count))\n",
    "print('number of support vectors = %d\\n' % len(classifier.dual_coef_.data))\n",
    "\n",
    "for alpha, count in sorted(alpha_count.items(), key=lambda x:(x[1], abs(x[0])), reverse=True)[:50]:\n",
    "    print('alpha= %.3f, count=%d (%.3f)' % (alpha, count, count/classifier.n_support_.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2506, 2506], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Support Vector Machine은 약 30%의 매우 높은 support vector를 모델에 저장하고 있으며, 각각 support vector의 가중치 역시 다르지 않다. negative는 모두 -0.1, positive는 모두 0.1 weight를 가지고 있다. k-NN classifier와 다르지 않을 정도의 support vector ratio이며, 질 좋은 support vector를 선택하지도 (equal alpha) 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regularization을 약하게 하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = (15106, 2770)\n",
      "y shape = (15106,)\n",
      "# features = 2770\n",
      "# L words = 15106\n"
     ]
    }
   ],
   "source": [
    "with open('../models/Support Vector Machine (rbf, C=10.0) norml30_r15.pkl', 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "    \n",
    "from py.utils import load_data\n",
    "head = 'l30_r15'\n",
    "directory = '../data/'\n",
    "x, y, x_words, vocabs = load_data(head, directory)\n",
    "x = x.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20243611809876871"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of Support vector \n",
    "classifier.n_support_.sum() / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of alphas = 22\n",
      "number of support vectors = 3058\n",
      "\n",
      "alpha= -10.000, count=1521 (0.497)\n",
      "alpha= 10.000, count=1517 (0.496)\n",
      "alpha= -9.893, count=1 (0.000)\n",
      "alpha= 8.672, count=1 (0.000)\n",
      "alpha= 7.519, count=1 (0.000)\n",
      "alpha= 6.975, count=1 (0.000)\n",
      "alpha= -6.911, count=1 (0.000)\n",
      "alpha= 6.827, count=1 (0.000)\n",
      "alpha= 6.430, count=1 (0.000)\n",
      "alpha= 5.897, count=1 (0.000)\n",
      "alpha= 5.053, count=1 (0.000)\n",
      "alpha= 4.676, count=1 (0.000)\n",
      "alpha= -4.607, count=1 (0.000)\n",
      "alpha= 4.067, count=1 (0.000)\n",
      "alpha= -4.058, count=1 (0.000)\n",
      "alpha= 3.924, count=1 (0.000)\n",
      "alpha= -3.089, count=1 (0.000)\n",
      "alpha= 2.861, count=1 (0.000)\n",
      "alpha= 2.806, count=1 (0.000)\n",
      "alpha= 1.297, count=1 (0.000)\n",
      "alpha= 1.081, count=1 (0.000)\n",
      "alpha= 0.474, count=1 (0.000)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "alpha_count = Counter(classifier.dual_coef_.data)\n",
    "print('number of alphas = %d' % len(alpha_count))\n",
    "print('number of support vectors = %d\\n' % len(classifier.dual_coef_.data))\n",
    "\n",
    "for alpha, count in sorted(alpha_count.items(), key=lambda x:(x[1], abs(x[0])), reverse=True)[:50]:\n",
    "    print('alpha= %.3f, count=%d (%.3f)' % (alpha, count, count/classifier.n_support_.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization 을 약하게 걸어도 대부분은 -10, 10의 weight를 가지며, support vector ratio가 20%로 줄어들었지만 여전히 많은 숫자이다. instance learning과 다르지 않다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
