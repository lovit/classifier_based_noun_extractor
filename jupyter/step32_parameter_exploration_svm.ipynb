{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반화 성능도 있기 때문에 전체 데이터셋에 대해서 성능 평가를 해봐야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = (15105, 2770)\n",
      "y shape = (15105,)\n",
      "# features = 2770\n",
      "# L words = 15105\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../models/SVC (C=0.1) norml30_r15.pkl', 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "    \n",
    "from py.utils import load_data\n",
    "head = 'l30_r15'\n",
    "directory = '../data/'\n",
    "x, y, x_words, vocabs = load_data(head, directory)\n",
    "x = x.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[9769,   64,   14, ...,   31,   34,  316]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sample_r(li, topk=5):\n",
    "    nonzero = x[li,:].nonzero()[1]\n",
    "    base = min(50, len(nonzero)//2)\n",
    "    return [vocabs[r] for r in sorted(nonzero, key=lambda x:word_frequency[0,x], reverse=True)[base:base+topk]]\n",
    "\n",
    "word_frequency = x.sum(axis=0)\n",
    "word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5012)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# sparse matrix type\n",
    "print(classifier.dual_coef_.shape)\n",
    "\n",
    "# sum = 0 ?? alpha sum은 1아닌가?\n",
    "print(classifier.dual_coef_.data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5012, 2770)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vectors\n",
    "classifier.support_vectors_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33181065872227739"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of Support vector \n",
    "classifier.n_support_.sum() / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     9,    14, ..., 15082, 15085, 15087], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector row id\n",
    "classifier.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행해(다) - ['오던', '진다는', '졌을', '지던', '졌다는'] (-0.100)\n",
      "올라서(다) - ['다가', '기도', '니', '자', '려고'] (-0.100)\n",
      "거들(다) - ['러', '었고', '었다는', '었다고', '었지만'] (-0.100)\n",
      "하(다) - ['기가', '든', '기만', '든지', '려'] (-0.100)\n",
      "심심찮(다) - ['게'] (-0.100)\n",
      "터져(다) - ['버리는', '나가는', '날', '나갈', '나오는'] (-0.100)\n",
      "거쳤(다) - ['는데', '으며', '는지', '으나', '음을'] (-0.100)\n",
      "덩달(다) - ['아서'] (-0.100)\n",
      "빌리(다) - ['러', '려는', '곤', '기가', '든지'] (-0.100)\n",
      "계셨(다) - ['는지', '더라도', '으니', '기에', '으니까'] (-0.100)\n",
      "우스꽝스러(다) - ['움을', '움이'] (-0.100)\n",
      "모아(다) - ['져야', '지게', '두고', '지면', '잡은'] (-0.100)\n",
      "지켜보(다) - ['곤', '기가', '기만', '려', '았을'] (-0.100)\n",
      "끼어들(다) - ['기를', '었기', '었지만', '려', '긴'] (-0.100)\n",
      "찌들(다) - ['었던', '구', '었고', '어진', '려'] (-0.100)\n",
      "굽히(다) - ['기도', '자', '거나', '지는', '려는'] (-0.100)\n",
      "빼내(다) - ['고는', '러', '려는', '듯', '기는'] (-0.100)\n",
      "아름다(다) - ['우며', '움의', '워도', '움에', '우면서도'] (-0.100)\n",
      "앞섰(다) - ['다고', '다', '지만', '으나', '음을'] (-0.100)\n",
      "마셔(다) - ['버리고', '서가', '대는', '서인지', '줘야'] (-0.100)\n",
      "망설이(다) - ['자', '거나', '지도', '는지', '더니'] (-0.100)\n",
      "버둥거리(다) - ['면서', '다', '는데', '다가', '기도'] (-0.100)\n",
      "죽치(다) - ['구', '니까'] (-0.100)\n",
      "찾아다니(다) - ['는데', '다가', '거나', '어도', '란'] (-0.100)\n",
      "들이밀(다) - ['기도', '어야', '자', '거나', '어도'] (-0.100)\n",
      "굵(다) - ['었지만', '기만', '긴', '단', '어져'] (-0.100)\n",
      "줄어드(다) - ['는데다가'] (-0.100)\n",
      "볶(다) - ['아야', '지도', '으면서', '듯이', '았을'] (-0.100)\n",
      "파(다) - ['는가', '자는', '주고', '온', '놓고'] (-0.100)\n",
      "걸(다) - ['겠다는', '듯이', '곤', '기가', '었기'] (-0.100)\n",
      "파헤쳐(다) - ['져', '지고', '놓고', '지지', '지자'] (-0.100)\n",
      "싫어하(다) - ['거나', '지는', '지도', '는지', '면서도'] (-0.100)\n",
      "커지(다) - ['기도', '자', '거나', '지는', '고는'] (-0.100)\n",
      "깨우치(다) - ['도록', '라는', '기도', '듯이', '곤'] (-0.100)\n",
      "맡(다) - ['았기', '기에는', '으면서도', '으려', '았는데'] (-0.100)\n",
      "흘러내리(다) - ['면서', '다가', '기도', '거나', '진'] (-0.100)\n",
      "흐느끼(다) - ['듯', '면서도', '듯이', '곤', '기만'] (-0.100)\n",
      "맺(다) - ['었으나', '으려', '었다', '어지고', '어가는'] (-0.100)\n",
      "떨어뜨리(다) - ['자', '거나', '지는', '려고', '고는'] (-0.100)\n",
      "뿌리치(다) - ['지는', '지도', '려고', '고는', '더니'] (-0.100)\n"
     ]
    }
   ],
   "source": [
    "base = 0\n",
    "topk = 40\n",
    "for idx, l in sorted(enumerate(classifier.support_), key=lambda x:abs(classifier.dual_coef_[0,x[0]]), reverse=True)[base :base + topk]:\n",
    "    print('%s%s - %s (%.3f)' % (x_words[l], '' if y[l] == 1 else '(다)', get_sample_r(l), classifier.dual_coef_[0,idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of alphas = 2\n",
      "number of support vectors = 5012\n",
      "\n",
      "alpha= -0.100, count=2506 (0.500)\n",
      "alpha= 0.100, count=2506 (0.500)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "alpha_count = Counter(classifier.dual_coef_.data)\n",
    "print('number of alphas = %d' % len(alpha_count))\n",
    "print('number of support vectors = %d\\n' % len(classifier.dual_coef_.data))\n",
    "\n",
    "for alpha, count in sorted(alpha_count.items(), key=lambda x:(x[1], abs(x[0])), reverse=True)[:50]:\n",
    "    print('alpha= %.3f, count=%d (%.3f)' % (alpha, count, count/classifier.n_support_.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2506, 2506], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Support Vector Machine은 약 30%의 매우 높은 support vector를 모델에 저장하고 있으며, 각각 support vector의 가중치 역시 다르지 않다. negative는 모두 -0.1, positive는 모두 0.1 weight를 가지고 있다. k-NN classifier와 다르지 않을 정도의 support vector ratio이며, 질 좋은 support vector를 선택하지도 (equal alpha) 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regularization을 약하게 하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = (15105, 2770)\n",
      "y shape = (15105,)\n",
      "# features = 2770\n",
      "# L words = 15105\n"
     ]
    }
   ],
   "source": [
    "with open('../models/Support Vector Machine (rbf, C=10.0) norml30_r15.pkl', 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "    \n",
    "from py.utils import load_data\n",
    "head = 'l30_r15'\n",
    "directory = '../data/'\n",
    "x, y, x_words, vocabs = load_data(head, directory)\n",
    "x = x.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20231711353856338"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of Support vector \n",
    "classifier.n_support_.sum() / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of alphas = 21\n",
      "number of support vectors = 3056\n",
      "\n",
      "alpha= -10.000, count=1521 (0.498)\n",
      "alpha= 10.000, count=1516 (0.496)\n",
      "alpha= -9.387, count=1 (0.000)\n",
      "alpha= -9.067, count=1 (0.000)\n",
      "alpha= 8.963, count=1 (0.000)\n",
      "alpha= 8.795, count=1 (0.000)\n",
      "alpha= 8.257, count=1 (0.000)\n",
      "alpha= 7.931, count=1 (0.000)\n",
      "alpha= 6.875, count=1 (0.000)\n",
      "alpha= -6.653, count=1 (0.000)\n",
      "alpha= 6.621, count=1 (0.000)\n",
      "alpha= 6.444, count=1 (0.000)\n",
      "alpha= 6.254, count=1 (0.000)\n",
      "alpha= 5.404, count=1 (0.000)\n",
      "alpha= 3.746, count=1 (0.000)\n",
      "alpha= 3.379, count=1 (0.000)\n",
      "alpha= 3.113, count=1 (0.000)\n",
      "alpha= -2.526, count=1 (0.000)\n",
      "alpha= 2.069, count=1 (0.000)\n",
      "alpha= -1.434, count=1 (0.000)\n",
      "alpha= 1.218, count=1 (0.000)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "alpha_count = Counter(classifier.dual_coef_.data)\n",
    "print('number of alphas = %d' % len(alpha_count))\n",
    "print('number of support vectors = %d\\n' % len(classifier.dual_coef_.data))\n",
    "\n",
    "for alpha, count in sorted(alpha_count.items(), key=lambda x:(x[1], abs(x[0])), reverse=True)[:50]:\n",
    "    print('alpha= %.3f, count=%d (%.3f)' % (alpha, count, count/classifier.n_support_.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization 을 약하게 걸어도 대부분은 -10, 10의 weight를 가지며, support vector ratio가 20%로 줄어들었지만 여전히 많은 숫자이다. instance learning과 다르지 않다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
