{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear kernel과 RBF kernel은 왜 서로 다른 비율로 support vector를 선택하게 되는가? (왜 linear kernel만 sparse support vector를 지니는가?) \n",
    "\n",
    "좀 더 자세하게 linear kernel과 rbf kernel을 썼을 때 각각 어떤 classification boundary를 따는 걸까? \n",
    "\n",
    "l30_r15 데이터로만 한 번 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = (15106, 2770)\n",
      "y shape = (15106,)\n",
      "# features = 2770\n",
      "# L words = 15106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize\n",
    "from py.utils import load_data\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "directory = '../data/'\n",
    "head = 'l30_r15'\n",
    "\n",
    "x, y, x_words, vocabs = load_data(head, directory)\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "B = csr_matrix(([1]*len(x.data), (x.nonzero()[0], x.nonzero()[1])))\n",
    "df_vocabs = B.sum(axis=0).tolist()[0]\n",
    "\n",
    "x = normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% support vector 0.027\n"
     ]
    }
   ],
   "source": [
    "svm_linear = SVC(C=1.0, kernel='linear')\n",
    "svm_linear.fit(x, y)\n",
    "print('%s support vector %.3f' % ('%', svm_linear.n_support_.sum()/x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% support vector 0.332\n"
     ]
    }
   ],
   "source": [
    "svm_rbf = SVC(C=1.0, kernel='rbf')\n",
    "svm_rbf.fit(x, y)\n",
    "print('%s support vector %.3f' % ('%', svm_rbf.n_support_.sum()/x.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear kernel을 알아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg = svm_linear.support_[:svm_linear.n_support_[0]].tolist()\n",
    "pos = svm_linear.support_[svm_linear.n_support_[0]:].tolist()\n",
    "\n",
    "neg_words = [x_words[i] for i in neg]\n",
    "pos_words = [x_words[i] for i in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B_pos = B[pos]\n",
    "B_pos.data = np.asarray([1]*len(B_pos.data))\n",
    "used_df_pos = B_pos.sum(axis=0).tolist()[0]\n",
    "used_pos_features = {j for j, df in enumerate(used_df_pos) if df > 0}\n",
    "n_used_pos_features = len(used_pos_features)\n",
    "average_pos_feature_df = sum([i for i in used_df_pos if i > 0]) / n_used_pos_features\n",
    "\n",
    "B_neg = B[neg]\n",
    "B_neg.data = np.asarray([1]*len(B_neg.data))\n",
    "used_df_neg = B_neg.sum(axis=0).tolist()[0]\n",
    "used_neg_features = {j for j, df in enumerate(used_df_neg) if df > 0}\n",
    "n_used_neg_features = len(used_neg_features)\n",
    "average_neg_feature_df = sum([i for i in used_df_neg if i > 0]) / n_used_neg_features\n",
    "\n",
    "used_features = {j for j in used_pos_features}\n",
    "used_features.update({j for j in used_neg_features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n used pos features= 622, average df = 4.29\n",
      "n used neg features= 1030, average df = 3.71\n",
      "n used features= 1442\n"
     ]
    }
   ],
   "source": [
    "print('n used pos features= %d, average df = %.2f' % (n_used_pos_features, average_pos_feature_df))\n",
    "print('n used neg features= %d, average df = %.2f' % (n_used_neg_features, average_neg_feature_df))\n",
    "print('n used features= %d' % len(used_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used in top 500 features= 73\n",
      "used in bottom 1000 features= 368\n"
     ]
    }
   ],
   "source": [
    "n_nouse_in_top_features = 0\n",
    "for j, vocab in sorted(enumerate(vocabs), key=lambda x:df_vocabs[x[0]], reverse=True)[:500]:\n",
    "    if not (j in used_features):\n",
    "        n_nouse_in_top_features += 1\n",
    "#         print('%s (df= %d, used= %r)' % (vocab, df_vocabs[j], j in used_features))\n",
    "\n",
    "# print('\\n%s\\n' % ('-'*80))\n",
    "n_use_in_bottom_features = 0\n",
    "for j, vocab in sorted(enumerate(vocabs), key=lambda x:df_vocabs[x[0]], reverse=False)[:1000]:\n",
    "    if (j in used_features):\n",
    "        n_use_in_bottom_features += 1\n",
    "#         print('%s (df= %d, used= %r)' % (vocab, df_vocabs[j], j in used_features))\n",
    "        \n",
    "print('used in top 500 features= %d' % n_nouse_in_top_features)\n",
    "print('used in bottom 1000 features= %d' % n_use_in_bottom_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 100, used= 99 (99.000)\n",
      "top 200, used= 194 (97.000)\n",
      "top 300, used= 274 (91.333)\n",
      "top 400, used= 353 (88.250)\n",
      "top 500, used= 427 (85.400)\n",
      "top 600, used= 495 (82.500)\n",
      "top 700, used= 561 (80.143)\n",
      "top 800, used= 621 (77.625)\n",
      "top 900, used= 679 (75.444)\n",
      "top 1000, used= 730 (73.000)\n",
      "top 1100, used= 775 (70.455)\n",
      "top 1200, used= 822 (68.500)\n",
      "top 1300, used= 876 (67.385)\n",
      "top 1400, used= 928 (66.286)\n",
      "top 1500, used= 965 (64.333)\n",
      "top 1600, used= 1008 (63.000)\n",
      "top 1700, used= 1046 (61.529)\n",
      "top 1800, used= 1080 (60.000)\n",
      "top 1900, used= 1117 (58.789)\n",
      "top 2000, used= 1157 (57.850)\n",
      "top 2100, used= 1204 (57.333)\n",
      "top 2200, used= 1244 (56.545)\n",
      "top 2300, used= 1280 (55.652)\n",
      "top 2400, used= 1317 (54.875)\n",
      "top 2500, used= 1359 (54.360)\n",
      "top 2600, used= 1392 (53.538)\n",
      "top 2700, used= 1425 (52.778)\n"
     ]
    }
   ],
   "source": [
    "n_used_order_by_df = 0\n",
    "for n, (j, vocab) in enumerate(sorted(enumerate(vocabs), key=lambda x:df_vocabs[x[0]], reverse=True)):\n",
    "    if (j in used_features):\n",
    "        n_used_order_by_df += 1\n",
    "    if (n + 1) % 100 == 0:\n",
    "        print('top %d, used= %d (%.3f)' % (n+1, n_used_order_by_df, 100*n_used_order_by_df/(n+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of alphas = 130\n",
      "number of support vectors = 405\n",
      "\n",
      "alpha= 1.000, count=143 (0.353)\n",
      "alpha= -1.000, count=134 (0.331)\n",
      "... count=1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "alpha_count = Counter(svm_linear.dual_coef_.data)\n",
    "print('number of alphas = %d' % len(alpha_count))\n",
    "print('number of support vectors = %d\\n' % len(svm_linear.dual_coef_.data))\n",
    "\n",
    "for alpha, count in sorted(alpha_count.items(), key=lambda x:(x[1], abs(x[0])), reverse=True)[:50]:\n",
    "    if count == 1: \n",
    "        print('... count=1')\n",
    "        break\n",
    "    print('alpha= %.3f, count=%d (%.3f)' % (alpha, count, count/svm_linear.n_support_.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
