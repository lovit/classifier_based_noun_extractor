{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from py.utils import load_data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heads = ['l30_r15', 'l10_r10', 'l5_r5']\n",
    "directory = '../data/'\n",
    "n_cv = 5\n",
    "performances = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression  + L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dataset = l30_r15 ##\n",
      "x shape = (15105, 2770)\n",
      "y shape = (15105,)\n",
      "# features = 2770\n",
      "# L words = 15105\n",
      "\n",
      "cost= 10000.00: [ 0.99702184  0.99702085  0.99503476  0.99668984  0.99569536]\n",
      "\n",
      "cost= 100.00: [ 0.99702184  0.99702085  0.99503476  0.99668984  0.99569536]\n",
      "\n",
      "cost= 4.00: [ 0.99702184  0.99702085  0.99503476  0.99668984  0.99569536]\n",
      "\n",
      "cost= 1.00: [ 0.99702184  0.99702085  0.99503476  0.99668984  0.99569536]\n",
      "\n",
      "cost= 0.25: [ 0.99702184  0.99702085  0.99503476  0.99668984  0.99569536]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l10_r10 ##\n",
      "x shape = (31544, 3515)\n",
      "y shape = (31544,)\n",
      "# features = 3515\n",
      "# L words = 31544\n",
      "\n",
      "cost= 10000.00: [ 0.99429387  0.99239182  0.99381835  0.99524489  0.99112238]\n",
      "\n",
      "cost= 100.00: [ 0.99429387  0.99239182  0.99381835  0.99524489  0.99112238]\n",
      "\n",
      "cost= 4.00: [ 0.99429387  0.99239182  0.99381835  0.99524489  0.99112238]\n",
      "\n",
      "cost= 1.00: [ 0.99429387  0.99239182  0.99381835  0.99524489  0.99112238]\n",
      "\n",
      "cost= 0.25: [ 0.99429387  0.99239182  0.99381835  0.99524489  0.99112238]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l5_r5 ##\n",
      "x shape = (50229, 5361)\n",
      "y shape = (50229,)\n",
      "# features = 5361\n",
      "# L words = 50229\n",
      "\n",
      "cost= 10000.00: [ 0.98526777  0.98447143  0.98457097  0.98695998  0.98556496]\n",
      "\n",
      "cost= 100.00: [ 0.98526777  0.98447143  0.98457097  0.98695998  0.98556496]\n",
      "\n",
      "cost= 4.00: [ 0.98526777  0.98447143  0.98457097  0.98695998  0.98556496]\n",
      "\n",
      "cost= 1.00: [ 0.98526777  0.98447143  0.98457097  0.98695998  0.98556496]\n",
      "\n",
      "cost= 0.25: [ 0.98526777  0.98447143  0.98457097  0.98695998  0.98556496]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for head in heads:\n",
    "    print('## dataset = %s ##' % head)\n",
    "    x, y, x_words, vocabs = load_data(head, directory)\n",
    "    for cost in [10000.0, 100.0, 4.0, 1.0, 0.25]:\n",
    "        classifier = LogisticRegression(penalty='l2', C=1)\n",
    "        scores = cross_val_score(classifier, x, y, cv=n_cv)\n",
    "        print('\\ncost= %.2f: %s' % (cost, scores))\n",
    "\n",
    "        performances[('Logistic + L2 (C=%.2f)' % cost, head)] = scores\n",
    "        classifier.fit(x, y)\n",
    "        model_name = 'Logistic + L2 (C=%.2f) ' % cost + head\n",
    "        with open('../models/%s.pkl' % model_name, 'wb') as f:\n",
    "            pickle.dump(classifier, f)\n",
    "            \n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dataset = l30_r15 ##\n",
      "x shape = (15105, 2770)\n",
      "y shape = (15105,)\n",
      "# features = 2770\n",
      "# L words = 15105\n",
      "\n",
      "cost=4.00: [ 0.98444739  0.97053956  0.9774909   0.96789143  0.96754967]\n",
      "\n",
      "cost=1.00: [ 0.97551291  0.96954651  0.97252565  0.98510427  0.9615894 ]\n",
      "\n",
      "cost=0.25: [ 0.97584381  0.97649785  0.96292618  0.95663688  0.97516556]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l10_r10 ##\n",
      "x shape = (31544, 3515)\n",
      "y shape = (31544,)\n",
      "# features = 3515\n",
      "# L words = 31544\n",
      "\n",
      "cost=4.00: [ 0.95593596  0.95371691  0.95244888  0.95767951  0.94895371]\n",
      "\n",
      "cost=1.00: [ 0.95974005  0.94404819  0.94801078  0.95831352  0.94578313]\n",
      "\n",
      "cost=0.25: [ 0.94626724  0.93818355  0.94278016  0.9618006   0.9411858 ]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l5_r5 ##\n",
      "x shape = (50229, 5361)\n",
      "y shape = (50229,)\n",
      "# features = 5361\n",
      "# L words = 50229\n",
      "\n",
      "cost=4.00: [ 0.94584909  0.94933307  0.94883536  0.95251842  0.95102041]\n",
      "\n",
      "cost=1.00: [ 0.95162254  0.95401155  0.93898069  0.943261    0.93230463]\n",
      "\n",
      "cost=0.25: [ 0.94574955  0.94375871  0.9394784   0.94107107  0.92832255]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for head in heads:    \n",
    "    print('## dataset = %s ##' % head)\n",
    "    x, y, x_words, vocabs = load_data(head, directory)\n",
    "    for cost in [4, 1, 0.25]:\n",
    "        classifier = LogisticRegression(penalty='l1', C=cost, n_jobs=4)\n",
    "        scores = cross_val_score(classifier, x, y, cv=n_cv)\n",
    "        print('\\ncost=%.2f: %s' % (cost, scores))\n",
    "        \n",
    "        performances[('Logistic + L1 (C=%.1f)' % cost, head)] = scores        \n",
    "        model_name = 'Logistic + L1 (C=%.1f) ' % cost + head\n",
    "        classifier.fit(x, y)\n",
    "        with open('../models/%s.pkl' % model_name, 'wb') as f:\n",
    "            pickle.dump(classifier, f)   \n",
    "        with open('performance_logistic_regression.pkl', 'wb') as f:\n",
    "            pickle.dump(performances, f)    \n",
    "        \n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
