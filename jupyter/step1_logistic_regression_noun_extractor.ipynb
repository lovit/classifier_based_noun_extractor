{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from py.utils import load_data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heads = ['l30_r15', 'l10_r10', 'l5_r5']\n",
    "directory = '../data/'\n",
    "n_cv = 5\n",
    "performances = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression  + L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dataset = l30_r15 ##\n",
      "x shape = (15106, 2770)\n",
      "y shape = (15106,)\n",
      "# features = 2770\n",
      "# L words = 15106\n",
      "\n",
      "cost= 10000.00: [ 0.99702184  0.99635882  0.99635882  0.99668984  0.99437272]\n",
      "\n",
      "cost= 100.00: [ 0.99702184  0.99635882  0.99635882  0.99668984  0.99437272]\n",
      "\n",
      "cost= 4.00: [ 0.99702184  0.99635882  0.99635882  0.99668984  0.99437272]\n",
      "\n",
      "cost= 1.00: [ 0.99702184  0.99635882  0.99635882  0.99668984  0.99437272]\n",
      "\n",
      "cost= 0.25: [ 0.99702184  0.99635882  0.99635882  0.99668984  0.99437272]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l10_r10 ##\n",
      "x shape = (31546, 3515)\n",
      "y shape = (31546,)\n",
      "# features = 3515\n",
      "# L words = 31546\n",
      "\n",
      "cost= 10000.00: [ 0.99366086  0.99270998  0.99365985  0.99413536  0.99365885]\n",
      "\n",
      "cost= 100.00: [ 0.99366086  0.99270998  0.99365985  0.99413536  0.99365885]\n",
      "\n",
      "cost= 4.00: [ 0.99366086  0.99270998  0.99365985  0.99413536  0.99365885]\n",
      "\n",
      "cost= 1.00: [ 0.99366086  0.99270998  0.99365985  0.99413536  0.99365885]\n",
      "\n",
      "cost= 0.25: [ 0.99366086  0.99270998  0.99365985  0.99413536  0.99365885]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l5_r5 ##\n",
      "x shape = (50232, 5361)\n",
      "y shape = (50232,)\n",
      "# features = 5361\n",
      "# L words = 50232\n",
      "\n",
      "cost= 10000.00: [ 0.98507017  0.98447298  0.98387418  0.98039021  0.98397372]\n",
      "\n",
      "cost= 100.00: [ 0.98507017  0.98447298  0.98387418  0.98039021  0.98397372]\n",
      "\n",
      "cost= 4.00: [ 0.98507017  0.98447298  0.98387418  0.98039021  0.98397372]\n",
      "\n",
      "cost= 1.00: [ 0.98507017  0.98447298  0.98387418  0.98039021  0.98397372]\n",
      "\n",
      "cost= 0.25: [ 0.98507017  0.98447298  0.98387418  0.98039021  0.98397372]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for head in heads:\n",
    "    print('## dataset = %s ##' % head)\n",
    "    x, y, x_words, vocabs = load_data(head, directory)\n",
    "    for cost in [10000.0, 100.0, 4.0, 1.0, 0.25]:\n",
    "        classifier = LogisticRegression(penalty='l2', C=1)\n",
    "        scores = cross_val_score(classifier, x, y, cv=n_cv)\n",
    "        print('\\ncost= %.2f: %s' % (cost, scores))\n",
    "\n",
    "        performances[('Logistic + L2 (C=%.2f)' % cost, head)] = scores\n",
    "        classifier.fit(x, y)\n",
    "        model_name = 'Logistic + L2 (C=%.2f) ' % cost + head\n",
    "        with open('../models/%s.pkl' % model_name, 'wb') as f:\n",
    "            pickle.dump(classifier, f)\n",
    "            \n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dataset = l30_r15 ##\n",
      "x shape = (15106, 2770)\n",
      "y shape = (15106,)\n",
      "# features = 2770\n",
      "# L words = 15106\n",
      "\n",
      "cost=4.00: [ 0.96988749  0.98080106  0.97053956  0.97451175  0.97947699]\n",
      "\n",
      "cost=1.00: [ 0.97617472  0.9652433   0.97649785  0.95796094  0.96954651]\n",
      "\n",
      "cost=0.25: [ 0.96459298  0.96722939  0.96987752  0.95365773  0.97881496]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l10_r10 ##\n",
      "x shape = (31546, 3515)\n",
      "y shape = (31546,)\n",
      "# features = 3515\n",
      "# L words = 31546\n",
      "\n",
      "cost=4.00: [ 0.94944532  0.94928685  0.95641148  0.96386115  0.95608751]\n",
      "\n",
      "cost=1.00: [ 0.92139461  0.94706815  0.95926454  0.94991282  0.94277108]\n",
      "\n",
      "cost=0.25: [ 0.9459588   0.95340729  0.94626724  0.9362815   0.94816107]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l5_r5 ##\n",
      "x shape = (50232, 5361)\n",
      "y shape = (50232,)\n",
      "# features = 5361\n",
      "# L words = 50232\n",
      "\n",
      "cost=4.00: [ 0.94316711  0.95033343  0.94863627  0.95829186  0.95699781]\n",
      "\n",
      "cost=1.00: [ 0.94625261  0.94316711  0.93251045  0.94783994  0.95570376]\n",
      "\n",
      "cost=0.25: [ 0.91738828  0.93868817  0.93479992  0.95251842  0.95032849]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for head in heads:    \n",
    "    print('## dataset = %s ##' % head)\n",
    "    x, y, x_words, vocabs = load_data(head, directory)\n",
    "    for cost in [4, 1, 0.25]:\n",
    "        classifier = LogisticRegression(penalty='l1', C=cost, n_jobs=4)\n",
    "        scores = cross_val_score(classifier, x, y, cv=n_cv)\n",
    "        print('\\ncost=%.2f: %s' % (cost, scores))\n",
    "        \n",
    "        performances[('Logistic + L1 (C=%.1f)' % cost, head)] = scores        \n",
    "        model_name = 'Logistic + L1 (C=%.1f) ' % cost + head\n",
    "        classifier.fit(x, y)\n",
    "        with open('../models/%s.pkl' % model_name, 'wb') as f:\n",
    "            pickle.dump(classifier, f)   \n",
    "        with open('performance_logistic_regression.pkl', 'wb') as f:\n",
    "            pickle.dump(performances, f)    \n",
    "        \n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
