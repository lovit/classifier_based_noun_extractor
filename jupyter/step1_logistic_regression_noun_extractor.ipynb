{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from py.utils import load_data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heads = ['l30_r15', 'l10_r10', 'l5_r5']\n",
    "directory = '../data/'\n",
    "n_cv = 5\n",
    "performances = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression  + L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dataset = l30_r15 ##\n",
      "x shape = (15166, 2617)\n",
      "y shape = (15166,)\n",
      "# features = 2617\n",
      "# L words = 15166\n",
      "\n",
      "cost= 10000.00: [ 0.99274885  0.98944939  0.98846027  0.99109792  0.99109792]\n",
      "\n",
      "cost= 100.00: [ 0.99274885  0.98944939  0.98846027  0.99109792  0.99109792]\n",
      "\n",
      "cost= 4.00: [ 0.99274885  0.98944939  0.98846027  0.99109792  0.99109792]\n",
      "\n",
      "cost= 1.00: [ 0.99274885  0.98944939  0.98846027  0.99109792  0.99109792]\n",
      "\n",
      "cost= 0.25: [ 0.99274885  0.98944939  0.98846027  0.99109792  0.99109792]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l10_r10 ##\n",
      "x shape = (31797, 3297)\n",
      "y shape = (31797,)\n",
      "# features = 3297\n",
      "# L words = 31797\n",
      "\n",
      "cost= 10000.00: [ 0.98600629  0.98396226  0.9852178   0.98222991  0.98364523]\n",
      "\n",
      "cost= 100.00: [ 0.98600629  0.98396226  0.9852178   0.98222991  0.98364523]\n",
      "\n",
      "cost= 4.00: [ 0.98600629  0.98396226  0.9852178   0.98222991  0.98364523]\n",
      "\n",
      "cost= 1.00: [ 0.98600629  0.98396226  0.9852178   0.98222991  0.98364523]\n",
      "\n",
      "cost= 0.25: [ 0.98600629  0.98396226  0.9852178   0.98222991  0.98364523]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l5_r5 ##\n",
      "x shape = (50764, 4995)\n",
      "y shape = (50764,)\n",
      "# features = 4995\n",
      "# L words = 50764\n",
      "\n",
      "cost= 10000.00: [ 0.96562592  0.97399783  0.97370235  0.97409633  0.97054768]\n",
      "\n",
      "cost= 100.00: [ 0.96562592  0.97399783  0.97370235  0.97409633  0.97054768]\n",
      "\n",
      "cost= 4.00: [ 0.96562592  0.97399783  0.97370235  0.97409633  0.97054768]\n",
      "\n",
      "cost= 1.00: [ 0.96562592  0.97399783  0.97370235  0.97409633  0.97054768]\n",
      "\n",
      "cost= 0.25: [ 0.96562592  0.97399783  0.97370235  0.97409633  0.97054768]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for head in heads:\n",
    "    print('## dataset = %s ##' % head)\n",
    "    x, y, x_words, vocabs = load_data(head, directory)\n",
    "    for cost in [10000.0, 100.0, 4.0, 1.0, 0.25]:\n",
    "        classifier = LogisticRegression(penalty='l2', C=1)\n",
    "        scores = cross_val_score(classifier, x, y, cv=n_cv)\n",
    "        print('\\ncost= %.2f: %s' % (cost, scores))\n",
    "\n",
    "        performances[('Logistic + L2 (C=%.2f)' % cost, head)] = scores\n",
    "        classifier.fit(x, y)\n",
    "        model_name = 'Logistic + L2 (C=%.2f) ' % cost + head\n",
    "        with open('../models/%s.pkl' % model_name, 'wb') as f:\n",
    "            pickle.dump(classifier, f)\n",
    "            \n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dataset = l30_r15 ##\n",
      "x shape = (15166, 2617)\n",
      "y shape = (15166,)\n",
      "# features = 2617\n",
      "# L words = 15166\n",
      "\n",
      "cost=4.00: [ 0.97000659  0.96801846  0.96241345  0.96900758  0.97230465]\n",
      "\n",
      "cost=1.00: [ 0.95912986  0.96702934  0.97065612  0.96636993  0.96604022]\n",
      "\n",
      "cost=0.25: [ 0.97429136  0.95746785  0.94625783  0.94724695  0.96604022]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l10_r10 ##\n",
      "x shape = (31797, 3297)\n",
      "y shape = (31797,)\n",
      "# features = 3297\n",
      "# L words = 31797\n",
      "\n",
      "cost=4.00: [ 0.96210692  0.94795597  0.9630445   0.95408083  0.95203648]\n",
      "\n",
      "cost=1.00: [ 0.95424528  0.94355346  0.95942758  0.93851234  0.93804057]\n",
      "\n",
      "cost=0.25: [ 0.93018868  0.94732704  0.95989936  0.93520994  0.9427583 ]\n",
      "--------------------------------------------------------------------------------\n",
      "## dataset = l5_r5 ##\n",
      "x shape = (50764, 4995)\n",
      "y shape = (50764,)\n",
      "# features = 4995\n",
      "# L words = 50764\n",
      "\n",
      "cost=4.00: [ 0.9517384   0.94701074  0.95203388  0.95104895  0.94808905]\n",
      "\n",
      "cost=1.00: [ 0.94139663  0.94573033  0.94494238  0.94799567  0.94109535]\n",
      "\n",
      "cost=0.25: [ 0.94573033  0.93538856  0.93972225  0.94425293  0.92927502]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for head in heads:    \n",
    "    print('## dataset = %s ##' % head)\n",
    "    x, y, x_words, vocabs = load_data(head, directory)\n",
    "    for cost in [4, 1, 0.25]:\n",
    "        classifier = LogisticRegression(penalty='l1', C=cost, n_jobs=4)\n",
    "        scores = cross_val_score(classifier, x, y, cv=n_cv)\n",
    "        print('\\ncost=%.2f: %s' % (cost, scores))\n",
    "        \n",
    "        performances[('Logistic + L1 (C=%.1f)' % cost, head)] = scores        \n",
    "        model_name = 'Logistic + L1 (C=%.1f) ' % cost + head\n",
    "        classifier.fit(x, y)\n",
    "        with open('../models/%s.pkl' % model_name, 'wb') as f:\n",
    "            pickle.dump(classifier, f)   \n",
    "        with open('performance_logistic_regression.pkl', 'wb') as f:\n",
    "            pickle.dump(performances, f)    \n",
    "        \n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
