{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = (15715, 4551)\n",
      "y shape = (15715,)\n",
      "# features = 4551\n",
      "# L words = 15715\n"
     ]
    }
   ],
   "source": [
    "head = 'l30_r15'\n",
    "directory = '../data/'\n",
    "model_fname ='../models/Logistic + L2 (C=1.00) norm l30_r15.pkl'\n",
    "\n",
    "\n",
    "import pickle    \n",
    "from py.utils import load_data\n",
    "\n",
    "x, y, x_words, vocabs = load_data(head, directory)\n",
    "with open(model_fname, 'rb') as f:\n",
    "    classifier = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficient = {vocabs[j]:coef for j, coef in enumerate(classifier.coef_[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('어오고', -0.0035026965225787533),\n",
       " ('어놓는', -0.0017447214860182797),\n",
       " ('느냐고', -0.027019952035748179),\n",
       " ('라느니', 0.0013030948275454116),\n",
       " ('으셔서', -0.3228328145095205)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(coefficient.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from soynlp.utils import get_process_memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TrainedNounExtractor:\n",
    "    def __init__(self, coefficient, max_length=8):\n",
    "        self._coef = coefficient\n",
    "        self.lmax = max_length\n",
    "        \n",
    "    def extract(self, sents, min_count=10, min_noun_score=0.1):\n",
    "        lrgraph = self._build_lrgraph(sents, min_count)\n",
    "        scores = self._compute_noun_score(lrgraph)\n",
    "        return scores, lrgraph\n",
    "        scores = self._postprocessing(lrgraph, scores)\n",
    "\n",
    "    def _build_lrgraph(self, sents, min_count, pruning_min_count=2):\n",
    "        lset = {}\n",
    "        rset = {}\n",
    "        for n_sent, sent in enumerate(sents):\n",
    "            for eojeol in sent.split():\n",
    "                for e in range(1, min(len(eojeol), self.lmax)+1):\n",
    "                    l = eojeol[:e]\n",
    "                    r = eojeol[e:]\n",
    "                    lset[l] = lset.get(l, 0) + 1\n",
    "                    rset[r] = rset.get(r, 0) + 1\n",
    "            if n_sent % 1000 == 999:\n",
    "                args = (n_sent+1, len(lset), len(rset), get_process_memory())\n",
    "                sys.stdout.write('\\rscaning vocabulary ... %d sents #(l= %d, r= %d), mem= %.3f Gb' % args)\n",
    "            if n_sent % 500000 == 499999:\n",
    "                lset = {l:f for l,f in lset.items() if f >= pruning_min_count}\n",
    "                rset = {l:f for l,f in rset.items() if f >= pruning_min_count}\n",
    "        lset = {l:f for l,f in lset.items() if f >= min_count}\n",
    "        rset = {l:f for l,f in lset.items() if f >= min_count}\n",
    "        \n",
    "        n_sents = n_sent\n",
    "        \n",
    "        lrgraph = {}\n",
    "        for n_sent, sent in enumerate(sents):\n",
    "            for eojeol in sent.split():\n",
    "                for e in range(1, min(len(eojeol), self.lmax)+1):\n",
    "                    l = eojeol[:e]\n",
    "                    r = eojeol[e:]\n",
    "                    if not (l in lset) or not (r in rset):\n",
    "                        continue\n",
    "                    rdict = lrgraph.get(l, {})\n",
    "                    rdict[r] = rdict.get(r, 0) + 1\n",
    "                    lrgraph[l] = rdict            \n",
    "            if n_sent % 1000 == 999:\n",
    "                args = (100*(n_sent+1)/n_sents, '%', n_sent+1, n_sents, get_process_memory())\n",
    "                sys.stdout.write('\\rbuilding lrgraph ... (%.3f %s, %d in %d), mem= %.3f Gb' % args)\n",
    "        args = (len(lset), len(rset), sum((len(rdict) for rdict in lrgraph.values())), get_process_memory())\n",
    "        print('\\rlrgraph has been built. (#L= %d, #R= %d, #E=%d), mem= %.3f Gb' % args)\n",
    "        return lrgraph\n",
    "        \n",
    "    def _compute_noun_score(self, lrgraph):\n",
    "        from collections import namedtuple\n",
    "        Score = namedtuple('Score', 'score frequency feature_fraction eojeol_fraction')\n",
    "        scores = {}\n",
    "        n = len(lrgraph)\n",
    "        for i, (l, rdict) in enumerate(lrgraph.items()):\n",
    "            rdict_ = {r:f for r,f in rdict.items() if r in self._coef}\n",
    "            rsum = sum((f for r,f in rdict.items() if r != ''))\n",
    "            frequency = rsum + rdict.get('', 0)\n",
    "            feature_fraction = sum(rdict_.values()) / rsum if rsum > 0 else 0\n",
    "            eojeol_fraction = 1 - rsum / frequency\n",
    "            if not rdict_:\n",
    "                score = 0\n",
    "            else:\n",
    "                score = sum(f*self._coef[r] for r, f in rdict_.items()) / sum(rdict_.values())\n",
    "            scores[l] = Score(score, frequency, feature_fraction, eojeol_fraction)\n",
    "            if (i+1) % 1000 == 0:\n",
    "                args = (100*(i+1)/n, '%', i+1, n)\n",
    "                sys.stdout.write('\\rcompute noun score ... (%.3f %s, %d in %d)' % args)\n",
    "        print('\\rcomputing noun score has been done.')\n",
    "        return sorted(scores.items(), key=lambda x:x[1].score, reverse=True)\n",
    "        \n",
    "    def _postprocessing(self, lrgraph, scores):\n",
    "        print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrgraph has been built. (#L= 201559, #R= 201559, #E=1601616), mem= 2.148 Gb\n",
      "computing noun score has been done.\n"
     ]
    }
   ],
   "source": [
    "from config import sentence_fname\n",
    "class Sentences:\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "    def __iter__(self):\n",
    "        with open(self.fname, encoding='utf-8') as f:\n",
    "            for doc in f:\n",
    "                yield doc.strip()\n",
    "\n",
    "sentences = Sentences(sentence_fname)\n",
    "noun_extractor = TrainedNounExtractor(coefficient)\n",
    "scores, lrgraph = noun_extractor.extract(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor, Postprocessing의 필요성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lrgraph를 만들 때 한글 외의 기호를 삭제한 어절로 이뤄져야 함 \n",
    "- N = Nsub + J problem\n",
    "    - 중세보편주 + {의, 의의}\n",
    "- [N+Jsub] + J problem\n",
    "    - 대학생과 + {'', 의}\n",
    "    - {의, 과의} 모두 조사\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'의': 6, '의의': 2}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrgraph['중세보편주']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 1, '의': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrgraph['대학생과']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('의적', 50),\n",
       " ('의', 27),\n",
       " ('의의', 14),\n",
       " ('의가', 8),\n",
       " ('의로', 4),\n",
       " ('의자', 2),\n",
       " ('의자와', 1),\n",
       " ('의해서', 1),\n",
       " ('의자는', 1),\n",
       " ('의자를', 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lrgraph['자유주'].items(), key=lambda x:x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('자유주',\n",
       "  Score(score=6.2108250932929217, frequency=113, feature_fraction=0.23893805309734514, eojeol_fraction=0.0)),\n",
       " ('우르',\n",
       "  Score(score=6.2108250932929217, frequency=130, feature_fraction=0.007692307692307693, eojeol_fraction=0.0)),\n",
       " ('낭만주',\n",
       "  Score(score=6.2108250932929217, frequency=107, feature_fraction=0.37383177570093457, eojeol_fraction=0.0)),\n",
       " ('권위주',\n",
       "  Score(score=6.2108250932929217, frequency=167, feature_fraction=0.47305389221556887, eojeol_fraction=0.0)),\n",
       " ('지역사',\n",
       "  Score(score=6.2108250932929217, frequency=241, feature_fraction=0.004149377593360996, eojeol_fraction=0.0)),\n",
       " ('민주주',\n",
       "  Score(score=6.2108250932929217, frequency=593, feature_fraction=0.3254637436762226, eojeol_fraction=0.0)),\n",
       " ('제국주',\n",
       "  Score(score=6.2108250932929217, frequency=258, feature_fraction=0.4069767441860465, eojeol_fraction=0.0)),\n",
       " ('공산주',\n",
       "  Score(score=6.2108250932929217, frequency=334, feature_fraction=0.5568862275449101, eojeol_fraction=0.0)),\n",
       " ('사회주',\n",
       "  Score(score=6.2108250932929217, frequency=788, feature_fraction=0.6256345177664975, eojeol_fraction=0.0)),\n",
       " ('일련',\n",
       "  Score(score=6.1914549763236986, frequency=334, feature_fraction=0.9610778443113772, eojeol_fraction=0.0))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x:x[1].frequency > 100 and len(x[0]) > 1, scores))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
