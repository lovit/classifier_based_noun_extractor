{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반화 성능도 있기 때문에 전체 데이터셋에 대해서 성능 평가를 해봐야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = (15166, 2617)\n",
      "y shape = (15166,)\n",
      "# features = 2617\n",
      "# L words = 15166\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../models/BernoulliNB norm l30_r15.pkl', 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "    \n",
    "from py.utils import load_data\n",
    "head = 'l30_r15'\n",
    "directory = '../data/'\n",
    "x, y, x_words, vocabs = load_data(head, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 39],\n",
       "        [215],\n",
       "        [118],\n",
       "        ..., \n",
       "        [129],\n",
       "        [ 35],\n",
       "        [ 36]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency = x.sum(axis=1)\n",
    "word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample_l(ri, topk=5):\n",
    "    nonzero = x[:,ri].nonzero()[0]\n",
    "    base = min(50, len(nonzero)//2)\n",
    "    return [x_words[l] for l in sorted(nonzero, key=lambda x:word_frequency[x,0], reverse=True)[base:base+topk]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coefficient = log prob\n",
    "\n",
    "==> exp(coefficient) = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16523803,  0.83476197])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(classifier.class_log_prior_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몸', '무엇', '얘기', '아버지', '모습'] - 의 (logp= -0.197, p= 0.821)\n",
      "['의미', '몸', '무엇', '얘기', '아버지'] - 에 (logp= -0.272, p= 0.762)\n",
      "['사회', '여기', '지금', '이야기', '안'] - 도 (logp= -0.567, p= 0.567)\n",
      "['죽', '다음', '이상', '아이들', '삶'] - 을 (logp= -0.595, p= 0.551)\n",
      "['책', '이들', '세상', '한국', '이름'] - 이 (logp= -0.612, p= 0.542)\n",
      "['모습', '길', '죽', '다음', '이상'] - 은 (logp= -0.685, p= 0.504)\n",
      "['밖', '쪽', '물', '적', '처음'] - 과 (logp= -0.809, p= 0.445)\n",
      "['얘기', '아버지', '모습', '길', '다음'] - 에서 (logp= -0.865, p= 0.421)\n",
      "['명', '주장', '입', '뜻', '발전'] - 으로 (logp= -1.016, p= 0.362)\n",
      "['예', '역사', '시', '존재', '머리'] - 를 (logp= -1.018, p= 0.361)\n",
      "['나가', '누구', '문화', '예', '역사'] - 가 (logp= -1.037, p= 0.354)\n",
      "['삶', '뒤', '나라', '정부', '자기'] - 는 (logp= -1.075, p= 0.341)\n",
      "['개', '남자', '생활', '학교', '자체'] - 로 (logp= -1.082, p= 0.339)\n",
      "['예', '역사', '시', '존재', '머리'] - 와 (logp= -1.187, p= 0.305)\n",
      "['아버지', '모습', '길', '다음', '이상'] - 인 (logp= -1.233, p= 0.291)\n",
      "['내용', '책', '이들', '세상', '한국'] - 이나 (logp= -1.301, p= 0.272)\n",
      "['데', '미국', '사랑', '관계', '자리'] - 하고 (logp= -1.426, p= 0.240)\n",
      "['자기', '돈', '데', '미국', '사랑'] - 에는 (logp= -1.431, p= 0.239)\n",
      "['몸', '무엇', '얘기', '아버지', '모습'] - 만 (logp= -1.432, p= 0.239)\n",
      "['길', '다음', '이상', '아이들', '삶'] - 까지 (logp= -1.497, p= 0.224)\n",
      "['의식', '전화', '결정', '결혼', '시장'] - 한 (logp= -1.599, p= 0.202)\n",
      "['행동', '의식', '전화', '결정', '결혼'] - 하는 (logp= -1.614, p= 0.199)\n",
      "['아이들', '삶', '뒤', '나라', '정부'] - 처럼 (logp= -1.645, p= 0.193)\n",
      "['뒤', '나라', '정부', '자기', '모르'] - 나 (logp= -1.673, p= 0.188)\n",
      "['결혼', '시장', '발견', '기능', '평가'] - 할 (logp= -1.674, p= 0.188)\n",
      "['처음', '생활', '글', '상황', '명'] - 이라는 (logp= -1.819, p= 0.162)\n",
      "['당신', '너', '남', '씨', '죽음'] - 에게 (logp= -1.837, p= 0.159)\n",
      "['길', '이상', '아이들', '삶', '사용'] - 보다 (logp= -1.839, p= 0.159)\n",
      "['미국', '사랑', '방법', '관계', '자리'] - 에도 (logp= -1.851, p= 0.157)\n",
      "['기억', '확인', '유지', '참여', '듯'] - 해 (logp= -1.862, p= 0.155)\n",
      "['관계', '자리', '이해', '힘', '내용'] - 에서는 (logp= -1.880, p= 0.153)\n",
      "['물', '적', '처음', '생활', '글'] - 이라고 (logp= -1.971, p= 0.139)\n",
      "['확인', '유지', '참여', '듯', '신문'] - 하여 (logp= -2.026, p= 0.132)\n",
      "['다음', '이상', '아이들', '삶', '뒤'] - 일 (logp= -2.065, p= 0.127)\n",
      "['유지', '참여', '듯', '경험', '구성'] - 하지 (logp= -2.137, p= 0.118)\n",
      "['유지', '참여', '듯', '경험', '구성'] - 하기 (logp= -2.142, p= 0.117)\n",
      "['듯', '경험', '구성', '조사', '준비'] - 하게 (logp= -2.145, p= 0.117)\n",
      "['세계', '어디', '시대', '변화', '개'] - 라는 (logp= -2.152, p= 0.116)\n",
      "['표현', '끝', '관심', '역할', '남편'] - 이란 (logp= -2.160, p= 0.115)\n",
      "['형성', '기록', '발생', '계속', '개발'] - 된 (logp= -2.183, p= 0.113)\n",
      "['삶', '뒤', '나라', '돈', '데'] - 이고 (logp= -2.259, p= 0.104)\n",
      "['적', '처음', '생활', '글', '상황'] - 이라 (logp= -2.317, p= 0.099)\n",
      "['방법', '관계', '이해', '힘', '내용'] - 이며 (logp= -2.343, p= 0.096)\n",
      "['세상', '한국', '이름', '시대', '과정'] - 에서도 (logp= -2.359, p= 0.095)\n",
      "['제시', '기술', '인정', '형성', '기록'] - 해야 (logp= -2.384, p= 0.092)\n",
      "['자리', '이해', '아이', '이유', '세계'] - 라고 (logp= -2.398, p= 0.091)\n",
      "['인정', '형성', '기록', '발생', '계속'] - 하면서 (logp= -2.433, p= 0.088)\n",
      "['자기', '돈', '데', '미국', '사랑'] - 보다는 (logp= -2.435, p= 0.088)\n",
      "['발생', '계속', '개발', '선택', '기대'] - 되는 (logp= -2.445, p= 0.087)\n",
      "['조사', '준비', '제시', '기술', '노래'] - 해서 (logp= -2.475, p= 0.084)\n",
      "['이해', '힘', '아이', '이유', '내용'] - 만을 (logp= -2.492, p= 0.083)\n",
      "['지적', '진행', '발표', '논의', '제공'] - 되어 (logp= -2.499, p= 0.082)\n",
      "['듯', '구성', '조사', '준비', '제시'] - 하며 (logp= -2.501, p= 0.082)\n",
      "['돈', '사랑', '방법', '관계', '자리'] - 만이 (logp= -2.540, p= 0.079)\n",
      "['교수', '지적', '진행', '반대', '발표'] - 되고 (logp= -2.551, p= 0.078)\n",
      "['방법', '자리', '이해', '내용', '책'] - 부터 (logp= -2.556, p= 0.078)\n",
      "['참여', '듯', '경험', '구성', '조사'] - 했던 (logp= -2.558, p= 0.077)\n",
      "['계획', '프로그램', '지적', '진행', '반대'] - 될 (logp= -2.564, p= 0.077)\n",
      "['거기', '글', '누구', '문화', '예'] - 로부터 (logp= -2.572, p= 0.076)\n",
      "['경험', '구성', '조사', '준비', '제시'] - 하면 (logp= -2.604, p= 0.074)\n",
      "['주장', '뜻', '발전', '표현', '관심'] - 과는 (logp= -2.625, p= 0.072)\n",
      "['노래', '인정', '형성', '기록', '발생'] - 한다는 (logp= -2.655, p= 0.070)\n",
      "['정부', '돈', '사랑', '방법', '관계'] - 이기 (logp= -2.693, p= 0.068)\n",
      "['상황', '명', '주장', '입', '뜻'] - 이라도 (logp= -2.718, p= 0.066)\n",
      "['과정', '일본', '밖', '쪽', '물'] - 에다 (logp= -2.752, p= 0.064)\n",
      "['날', '엄마', '현실', '너', '소설'] - 로서 (logp= -2.753, p= 0.064)\n",
      "['저', '지', '나가', '타', '누구'] - 란 (logp= -2.767, p= 0.063)\n",
      "['사건', '대상', '활동', '당신', '땅'] - 으로부터 (logp= -2.771, p= 0.063)\n",
      "['개발', '대답', '선택', '지적', '진행'] - 함으로써 (logp= -2.773, p= 0.062)\n",
      "['계속', '개발', '대답', '선택', '다양'] - 하거나 (logp= -2.801, p= 0.061)\n",
      "['글', '상황', '예', '역사', '시'] - 에서의 (logp= -2.833, p= 0.059)\n",
      "['시대', '변화', '일본', '밖', '쪽'] - 엔 (logp= -2.834, p= 0.059)\n",
      "['책', '세계', '세상', '한국', '이름'] - 에만 (logp= -2.848, p= 0.058)\n",
      "['방법', '관계', '힘', '아이', '내용'] - 인데 (logp= -2.859, p= 0.057)\n",
      "['땅', '남', '죽음', '문학', '자연'] - 과의 (logp= -2.880, p= 0.056)\n",
      "['기록', '발생', '계속', '개발', '대답'] - 하던 (logp= -2.884, p= 0.056)\n",
      "['제시', '작가', '아들', '개인', '의사'] - 에게는 (logp= -2.902, p= 0.055)\n",
      "['분석', '걱정', '규정', '확대', '생산'] - 되지 (logp= -2.941, p= 0.053)\n",
      "['세계', '세상', '이름', '시대', '과정'] - 이기도 (logp= -2.959, p= 0.052)\n",
      "['과정', '변화', '물', '생활', '학교'] - 조차 (logp= -2.971, p= 0.051)\n",
      "['형성', '기록', '발생', '개발', '대답'] - 하기도 (logp= -2.972, p= 0.051)\n",
      "['글', '상황', '명', '저', '주장'] - 이지만 (logp= -2.979, p= 0.051)\n",
      "['이름', '과정', '변화', '개', '생활'] - 마저 (logp= -2.982, p= 0.051)\n",
      "['지역', '운동', '교육', '영향', '노력'] - 으로는 (logp= -2.994, p= 0.050)\n",
      "['나가', '타', '누구', '문화', '예'] - 라 (logp= -3.001, p= 0.050)\n",
      "['지적', '반대', '발표', '지원', '제공'] - 했다는 (logp= -3.030, p= 0.048)\n",
      "['한국', '이름', '변화', '일본', '쪽'] - 인지 (logp= -3.046, p= 0.048)\n",
      "['아내', '뭐', '후', '목소리', '영화'] - 라도 (logp= -3.048, p= 0.047)\n",
      "['상황', '누구', '주장', '문화', '예'] - 임을 (logp= -3.053, p= 0.047)\n",
      "['선택', '기대', '계획', '전쟁', '지적'] - 했을 (logp= -3.065, p= 0.047)\n",
      "['세상', '이름', '시대', '변화', '쪽'] - 까지도 (logp= -3.076, p= 0.046)\n",
      "['날', '사건', '대상', '활동', '현실'] - 이라면 (logp= -3.080, p= 0.046)\n",
      "['책', '이들', '세상', '이름', '일본'] - 두 (logp= -3.085, p= 0.046)\n",
      "['이전', '차지', '강조', '성공', '연결'] - 하려는 (logp= -3.094, p= 0.045)\n",
      "['계속', '개발', '선택', '다양', '계획'] - 하도록 (logp= -3.099, p= 0.045)\n",
      "['부분', '기업', '선생님', '현상', '대통령'] - 으로서 (logp= -3.101, p= 0.045)\n",
      "['의사', '교수', '우리들', '환자', '우리나라'] - 한테 (logp= -3.129, p= 0.044)\n",
      "['반대', '발표', '논의', '지원', '제공'] - 했다고 (logp= -3.129, p= 0.044)\n",
      "['현실', '소설', '남', '죽음', '문학'] - 이었던 (logp= -3.136, p= 0.043)\n",
      "['파악', '조직', '발달', '방송', '실시'] - 돼 (logp= -3.138, p= 0.043)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "base = 0\n",
    "topk = 100\n",
    "for r, coef in sorted(enumerate(classifier.coef_[0]), key=lambda x:x[1], reverse=True)[base :base + topk]:\n",
    "    print('%s - %s (logp= %.3f, p= %.3f)' % (get_sample_l(r), vocabs[r], coef, np.exp(coef)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## BernoulliNB classifier code\n",
    "\n",
    "    def _joint_log_likelihood(self, X):\n",
    "        \"\"\"Calculate the posterior log probability of the samples X\"\"\"\n",
    "        check_is_fitted(self, \"classes_\")\n",
    "\n",
    "        X = check_array(X, accept_sparse='csr')\n",
    "\n",
    "        if self.binarize is not None:\n",
    "            X = binarize(X, threshold=self.binarize)\n",
    "\n",
    "        n_classes, n_features = self.feature_log_prob_.shape\n",
    "        n_samples, n_features_X = X.shape\n",
    "\n",
    "        if n_features_X != n_features:\n",
    "            raise ValueError(\"Expected input with %d features, got %d instead\"\n",
    "                             % (n_features, n_features_X))\n",
    "\n",
    "        neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
    "        # Compute  neg_prob · (1 - X).T  as  ∑neg_prob - X · neg_prob\n",
    "        jll = safe_sparse_dot(X, (self.feature_log_prob_ - neg_prob).T)\n",
    "        jll += self.class_log_prior_ + neg_prob.sum(axis=1)\n",
    "\n",
    "        return jll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes 역시 infrequent feature가 low scale\n",
    "\n",
    "classification rule: $ P(x_i \\mid y) = P(i \\mid y) x_i + (1 - P(i \\mid y)) (1 - x_i) $\n",
    "\n",
    "class y에서 feature i의 생성확률을 만들기 때문에 infrequent 한 feature가 작은 coefficient를 지님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011056705101879648"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(classifier.coef_[0,vocabs.index('해줌으로써')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
