{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반화 성능도 있기 때문에 전체 데이터셋에 대해서 성능 평가를 해봐야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = (15715, 4551)\n",
      "y shape = (15715,)\n",
      "# features = 4551\n",
      "# L words = 15715\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../models/BernoulliNB norm l30_r15.pkl', 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "    \n",
    "from py.utils import load_data\n",
    "head = 'l30_r15'\n",
    "directory = '../data/'\n",
    "x, y, x_words, vocabs = load_data(head, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[100],\n",
       "        [295],\n",
       "        [104],\n",
       "        ..., \n",
       "        [ 31],\n",
       "        [ 93],\n",
       "        [199]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency = x.sum(axis=1)\n",
    "word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample_l(ri, topk=5):\n",
    "    nonzero = x[:,ri].nonzero()[0]\n",
    "    base = min(50, len(nonzero)//2)\n",
    "    return [x_words[l] for l in sorted(nonzero, key=lambda x:word_frequency[x,0], reverse=True)[base:base+topk]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coefficient = log prob\n",
    "\n",
    "==> exp(coefficient) = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19987273,  0.80012727])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(classifier.class_log_prior_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안', '지금', '이상', '모습', '사용'] - 의 (logp= -0.184, p= 0.832)\n",
      "['어머니', '중', '이것', '여기', '사이'] - 에 (logp= -0.261, p= 0.770)\n",
      "['무엇', '보이', '마음', '얼굴', '전'] - 도 (logp= -0.595, p= 0.552)\n",
      "['지금', '이상', '맞', '모습', '사용'] - 을 (logp= -0.620, p= 0.538)\n",
      "['선생', '사랑', '삶', '돈', '데'] - 이 (logp= -0.647, p= 0.523)\n",
      "['지금', '이상', '맞', '모습', '사용'] - 은 (logp= -0.737, p= 0.479)\n",
      "['안', '이상', '모습', '사용', '길'] - 에서 (logp= -0.830, p= 0.436)\n",
      "['세상', '현실', '과정', '학생', '글'] - 과 (logp= -0.847, p= 0.429)\n",
      "['변화', '글', '존재', '누구', '시'] - 를 (logp= -0.941, p= 0.390)\n",
      "['시대', '문화', '친구', '어디', '개'] - 가 (logp= -0.951, p= 0.387)\n",
      "['죽', '사이', '사', '맞', '나오'] - 는 (logp= -1.020, p= 0.360)\n",
      "['이름', '여성', '한국', '세상', '과정'] - 으로 (logp= -1.041, p= 0.353)\n",
      "['어디', '현실', '개', '변화', '글'] - 로 (logp= -1.064, p= 0.345)\n",
      "['존재', '누구', '시', '저', '자체'] - 와 (logp= -1.125, p= 0.325)\n",
      "['죽', '사이', '안', '지금', '이상'] - 이다 (logp= -1.226, p= 0.293)\n",
      "['모습', '길', '다음', '세계', '자기'] - 인 (logp= -1.291, p= 0.275)\n",
      "['내용', '책', '힘', '뿐', '뜻'] - 이나 (logp= -1.305, p= 0.271)\n",
      "['몸', '선생', '자리', '사랑', '삶'] - 하고 (logp= -1.369, p= 0.254)\n",
      "['몸', '자리', '사랑', '뒤', '삶'] - 에는 (logp= -1.414, p= 0.243)\n",
      "['사이', '지금', '이상', '모습', '길'] - 만 (logp= -1.462, p= 0.232)\n",
      "['다음', '세계', '자기', '방법', '나라'] - 까지 (logp= -1.488, p= 0.226)\n",
      "['돈', '역사', '정부', '주장', '관계'] - 들이 (logp= -1.504, p= 0.222)\n",
      "['발견', '현상', '대답', '인식', '평가'] - 한 (logp= -1.550, p= 0.212)\n",
      "['관련', '노력', '방', '발견', '와'] - 하는 (logp= -1.572, p= 0.208)\n",
      "['놓', '찾', '어머니', '왔', '크'] - 나 (logp= -1.596, p= 0.203)\n",
      "['나라', '아버지', '몸', '선생', '자리'] - 처럼 (logp= -1.627, p= 0.197)\n",
      "['평가', '계속', '공부', '확인', '의식'] - 할 (logp= -1.648, p= 0.192)\n",
      "['관계', '내용', '이해', '이유', '책'] - 들을 (logp= -1.776, p= 0.169)\n",
      "['역사', '정부', '주장', '관계', '내용'] - 들은 (logp= -1.794, p= 0.166)\n",
      "['현실', '과정', '학생', '글', '처음'] - 이라는 (logp= -1.796, p= 0.166)\n",
      "['입장', '행동', '계획', '대표', '기억'] - 해 (logp= -1.816, p= 0.163)\n",
      "['나라', '몸', '자리', '사랑', '뒤'] - 에도 (logp= -1.838, p= 0.159)\n",
      "['여성', '세상', '현실', '과정', '학생'] - 이었다 (logp= -1.851, p= 0.157)\n",
      "['뒤', '삶', '역사', '데', '정부'] - 에서는 (logp= -1.856, p= 0.156)\n",
      "['길', '세계', '자기', '방법', '나라'] - 보다 (logp= -1.863, p= 0.155)\n",
      "['기업', '당신', '엄마', '대상', '국가'] - 에게 (logp= -1.934, p= 0.145)\n",
      "['과정', '학생', '글', '쪽', '처음'] - 이라고 (logp= -1.943, p= 0.143)\n",
      "['계획', '기억', '기술', '기능', '상대'] - 했다 (logp= -1.968, p= 0.140)\n",
      "['대표', '기억', '기술', '상대', '해결'] - 하여 (logp= -1.980, p= 0.138)\n",
      "['자연', '운동', '교육', '영화', '개인'] - 적 (logp= -2.036, p= 0.131)\n",
      "['뒤', '내', '역사', '데', '정부'] - 라는 (logp= -2.052, p= 0.128)\n",
      "['돈', '역사', '정부', '주장', '관계'] - 들 (logp= -2.083, p= 0.125)\n",
      "['길', '다음', '세계', '방법', '나라'] - 일 (logp= -2.094, p= 0.123)\n",
      "['대표', '기억', '기술', '기능', '상대'] - 하지 (logp= -2.108, p= 0.122)\n",
      "['기억', '기술', '기능', '상대', '해결'] - 하게 (logp= -2.109, p= 0.121)\n",
      "['상황', '명', '표현', '생활', '적'] - 이란 (logp= -2.118, p= 0.120)\n",
      "['여성', '학생', '개', '변화', '글'] - 들의 (logp= -2.123, p= 0.120)\n",
      "['해결', '제시', '지적', '포함', '기록'] - 한다 (logp= -2.126, p= 0.119)\n",
      "['기술', '기능', '상대', '해결', '제시'] - 하기 (logp= -2.133, p= 0.118)\n",
      "['몸', '자리', '사랑', '삶', '돈'] - 이며 (logp= -2.152, p= 0.116)\n",
      "['국가', '소설', '지역', '자연', '교육'] - 적인 (logp= -2.170, p= 0.114)\n",
      "['기록', '경험', '발생', '조사', '전화'] - 된 (logp= -2.180, p= 0.113)\n",
      "['아버지', '몸', '선생', '자리', '사랑'] - 이고 (logp= -2.181, p= 0.113)\n",
      "['존재', '시', '저', '자체', '학교'] - 였다 (logp= -2.185, p= 0.113)\n",
      "['자리', '두', '뒤', '내', '역사'] - 라고 (logp= -2.242, p= 0.106)\n",
      "['의식', '입장', '행동', '법', '계획'] - 하며 (logp= -2.308, p= 0.099)\n",
      "['과정', '학생', '글', '쪽', '처음'] - 이라 (logp= -2.308, p= 0.099)\n",
      "['나', '모르', '이렇', '여자', '이야기'] - 다 (logp= -2.326, p= 0.098)\n",
      "['내용', '이유', '책', '시대', '뜻'] - 에서도 (logp= -2.349, p= 0.095)\n",
      "['전화', '인정', '결혼', '유지', '구성'] - 하면서 (logp= -2.373, p= 0.093)\n",
      "['포함', '기록', '경험', '조사', '전화'] - 해야 (logp= -2.377, p= 0.093)\n",
      "['포함', '기록', '경험', '발생', '조사'] - 하였다 (logp= -2.408, p= 0.090)\n",
      "['자기', '방법', '나라', '몸', '선생'] - 인데 (logp= -2.413, p= 0.090)\n",
      "['선생', '자리', '사랑', '삶', '돈'] - 입니다 (logp= -2.425, p= 0.089)\n",
      "['상대', '해결', '제시', '분', '지적'] - 해서 (logp= -2.427, p= 0.088)\n",
      "['나라', '선생', '자리', '사랑', '삶'] - 보다는 (logp= -2.435, p= 0.088)\n",
      "['조사', '전화', '인정', '유지', '구성'] - 되는 (logp= -2.447, p= 0.087)\n",
      "['선택', '기대', '성공', '개발', '비교'] - 되어 (logp= -2.494, p= 0.083)\n",
      "['관계', '내용', '이해', '이유', '책'] - 만을 (logp= -2.517, p= 0.081)\n",
      "['노래', '형성', '준비', '선택', '교수'] - 되고 (logp= -2.519, p= 0.081)\n",
      "['기능', '상대', '해결', '제시', '지적'] - 했던 (logp= -2.526, p= 0.080)\n",
      "['역사', '데', '정부', '뭐', '내용'] - 부터 (logp= -2.542, p= 0.079)\n",
      "['해결', '제시', '지적', '포함', '기록'] - 하면 (logp= -2.545, p= 0.078)\n",
      "['형성', '준비', '선택', '기대', '성공'] - 될 (logp= -2.574, p= 0.076)\n",
      "['삶', '돈', '역사', '정부', '주장'] - 만이 (logp= -2.579, p= 0.076)\n",
      "['학생', '개', '변화', '글', '존재'] - 들도 (logp= -2.607, p= 0.074)\n",
      "['개', '변화', '글', '존재', '시'] - 들과 (logp= -2.614, p= 0.073)\n",
      "['경험', '발생', '조사', '전화', '인정'] - 한다는 (logp= -2.614, p= 0.073)\n",
      "['대표', '기술', '동시', '기능', '상대'] - 적으로 (logp= -2.623, p= 0.073)\n",
      "['요구', '머리', '연구', '역할', '엄마'] - 로서 (logp= -2.653, p= 0.070)\n",
      "['개', '변화', '지', '존재', '누구'] - 란 (logp= -2.668, p= 0.069)\n",
      "['설명', '물', '상황', '명', '표현'] - 이라도 (logp= -2.705, p= 0.067)\n",
      "['유지', '구성', '다양', '강조', '참여'] - 하거나 (logp= -2.718, p= 0.066)\n",
      "['자체', '학교', '생활', '거기', '예'] - 로부터 (logp= -2.719, p= 0.066)\n",
      "['책', '힘', '뜻', '이름', '친구'] - 에다 (logp= -2.728, p= 0.065)\n",
      "['일본', '물', '상황', '표현', '생활'] - 과는 (logp= -2.739, p= 0.065)\n",
      "['강조', '참여', '발표', '형성', '선택'] - 함으로써 (logp= -2.749, p= 0.064)\n",
      "['강조', '시장', '언어', '준비', '생명'] - 성 (logp= -2.750, p= 0.064)\n",
      "['뒤', '삶', '돈', '정부', '주장'] - 이기 (logp= -2.752, p= 0.064)\n",
      "['남', '입', '문학', '남편', '중심'] - 으로부터 (logp= -2.756, p= 0.064)\n",
      "['내용', '이해', '책', '남자', '힘'] - 인가 (logp= -2.760, p= 0.063)\n",
      "['학생', '글', '쪽', '처음', '물'] - 이야 (logp= -2.779, p= 0.062)\n",
      "['발생', '조사', '인정', '결혼', '유지'] - 했고 (logp= -2.791, p= 0.061)\n",
      "['비판', '비교', '진행', '분석', '증가'] - 된다 (logp= -2.806, p= 0.060)\n",
      "['시대', '문화', '이름', '한국', '세상'] - 엔 (logp= -2.813, p= 0.060)\n",
      "['상황', '밖', '자체', '학교', '만'] - 에서의 (logp= -2.815, p= 0.060)\n",
      "['뿐', '뜻', '이름', '친구', '여성'] - 이지만 (logp= -2.818, p= 0.060)\n",
      "['내용', '이해', '책', '힘', '시대'] - 에만 (logp= -2.841, p= 0.058)\n",
      "['유지', '강조', '참여', '시장', '발표'] - 하던 (logp= -2.855, p= 0.058)\n",
      "['애', '날', '부분', '남', '연구'] - 들에 (logp= -2.871, p= 0.057)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "base = 0\n",
    "topk = 100\n",
    "for r, coef in sorted(enumerate(classifier.coef_[0]), key=lambda x:x[1], reverse=True)[base :base + topk]:\n",
    "    print('%s - %s (logp= %.3f, p= %.3f)' % (get_sample_l(r), vocabs[r], coef, np.exp(coef)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## BernoulliNB classifier code\n",
    "\n",
    "    def _joint_log_likelihood(self, X):\n",
    "        \"\"\"Calculate the posterior log probability of the samples X\"\"\"\n",
    "        check_is_fitted(self, \"classes_\")\n",
    "\n",
    "        X = check_array(X, accept_sparse='csr')\n",
    "\n",
    "        if self.binarize is not None:\n",
    "            X = binarize(X, threshold=self.binarize)\n",
    "\n",
    "        n_classes, n_features = self.feature_log_prob_.shape\n",
    "        n_samples, n_features_X = X.shape\n",
    "\n",
    "        if n_features_X != n_features:\n",
    "            raise ValueError(\"Expected input with %d features, got %d instead\"\n",
    "                             % (n_features, n_features_X))\n",
    "\n",
    "        neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
    "        # Compute  neg_prob · (1 - X).T  as  ∑neg_prob - X · neg_prob\n",
    "        jll = safe_sparse_dot(X, (self.feature_log_prob_ - neg_prob).T)\n",
    "        jll += self.class_log_prior_ + neg_prob.sum(axis=1)\n",
    "\n",
    "        return jll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes 역시 infrequent feature가 low scale\n",
    "\n",
    "classification rule: $ P(x_i \\mid y) = P(i \\mid y) x_i + (1 - P(i \\mid y)) (1 - x_i) $\n",
    "\n",
    "class y에서 feature i의 생성확률을 만들기 때문에 infrequent 한 feature가 작은 coefficient를 지님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011132315521628507"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(classifier.coef_[0,vocabs.index('해줌으로써')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
